{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep dive into Tensorflow example “Partial Differential Equations”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow documentation provides very [nice tutorial examples](https://www.tensorflow.org/tutorials/). One of the non machine learning examples called [\"Partial Differential Equations\"](https://www.tensorflow.org/tutorials/non-ml/pdes), which models a surface of a pond as few raindrops land on it.\n",
    "\n",
    "Tensorflow code of this example is straightforward, but mathematics and physics behind is not. I can only imagine present physicist students, who can say from top of their head on what is going on in this example. So far i'm pretty sure they still would spend some time refreshing some necessary knowledge.\n",
    "\n",
    "I was a physicist student some time ago, so let me try to shed some light. As a discamiler i want to say that in some statements i potentially can be wrong, so far in general i have a sense of overall picture now (after 3 nights :) ).\n",
    "\n",
    "![](https://github.com/r7vme/tensorflow-example-pdes/blob/master/example.jpeg?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick source code explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original source code: https://www.tensorflow.org/tutorials/non-ml/pdes\n",
    "\n",
    "Extra changes:\n",
    "- added speed of the waves $c$\n",
    "- Laplacian kernel divided by 2 to be aligned with kernel from Wikipedia and other papers\n",
    "\n",
    "If you already know the code, then feel free to skip to [Mathematics](#Mathematics) section.\n",
    "\n",
    "In this example author tries to model a physical process that happens when rain drop hit a water surface. Tensorflow framework mostly used here to do a parallel linear algebra computations. As you know Tensorflow has two things in it's core: tensor and operation. Tensor is usually some vector (matrix) or scalar. Operation can be some linear algebra operation (e.g. matrix multiplication). Both of them are part (nodes) of internal TensorFlow graph. This graph can be executed within a TensorFlow session.\n",
    "\n",
    "So let's see what tensors and operations we need to model our physical process in TensorFlow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First import necessary libraries and define function that will draw a pond."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries for simulation\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "#Imports for visualization\n",
    "import PIL.Image\n",
    "from io import BytesIO\n",
    "from IPython.display import clear_output, Image, display\n",
    "\n",
    "\n",
    "def DisplayArray(a, fmt='jpeg', rng=[0,1]):\n",
    "  \"\"\"Display an array as a picture.\"\"\"\n",
    "  a = (a - rng[0])/float(rng[1] - rng[0])*255\n",
    "  a = np.uint8(np.clip(a, 0, 255))\n",
    "  f = BytesIO()\n",
    "  PIL.Image.fromarray(a).save(f, fmt)\n",
    "  clear_output(wait = True)\n",
    "  display(Image(data=f.getvalue()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then initialize Tensorflow session. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following two functions are necessary to perform operation called convolution. Convolutional kernel `k` slides the image `x` and produces new matrix `y`. Every `y` value is a sum of multiplication of area (covered by `k`) on `x` and kernel `k`.\n",
    "\n",
    "![](https://cdn-images-1.medium.com/max/1040/1*ZCjPUFrB6eHPRi4eyP6aaA.gif)\n",
    "[image source](https://towardsdatascience.com/intuitively-understanding-convolutions-for-deep-learning-1f6f42faee1)\n",
    "\n",
    "NOTE: In our case `y` will be the same shape as `x`, because padding set to `SAME`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_kernel(a):\n",
    "  \"\"\"Transform a 2D array into a convolution kernel\"\"\"\n",
    "  a = np.asarray(a)\n",
    "  a = a.reshape(list(a.shape) + [1,1])\n",
    "  return tf.constant(a, dtype=1)\n",
    "\n",
    "def simple_conv(x, k):\n",
    "  \"\"\"A simplified 2D convolution operation\"\"\"\n",
    "  x = tf.expand_dims(tf.expand_dims(x, 0), -1)\n",
    "  y = tf.nn.depthwise_conv2d(x, k, [1, 1, 1, 1], padding='SAME')\n",
    "  return y[0, :, :, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discrete Laplace operator described below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def laplace(x):\n",
    "  \"\"\"Compute the 2D laplacian of an array\"\"\"\n",
    "  laplace_k = make_kernel([[0.25, 0.5, 0.25],\n",
    "                           [0.5, -3., 0.5],\n",
    "                           [0.25, 0.5, 0.25]])\n",
    "  return simple_conv(x, laplace_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize pond `u_init` (500x500x1) with zeros. Also initialize matrix that will store first derivative `ut_unit`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 500\n",
    "\n",
    "# Initial Conditions -- some rain drops hit a pond\n",
    "\n",
    "# Set everything to zero\n",
    "u_init = np.zeros([N, N], dtype=np.float32)\n",
    "ut_init = np.zeros([N, N], dtype=np.float32)\n",
    "\n",
    "# Some rain drops hit a pond at random points\n",
    "for n in range(40):\n",
    "  a,b = np.random.randint(0, N, 2)\n",
    "  u_init[a,b] = np.random.uniform()\n",
    "\n",
    "DisplayArray(u_init, rng=[-0.1, 0.1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define TensorFlow input, variables and finally two operations. Then group them and run session. All details below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters:\n",
    "# eps -- time resolution\n",
    "# damping -- wave damping\n",
    "# c -- wave speed # Not a part of original code version\n",
    "eps = tf.placeholder(tf.float32, shape=())\n",
    "damping = tf.placeholder(tf.float32, shape=())\n",
    "c = tf.placeholder(tf.float32, shape=())\n",
    "\n",
    "# Create variables for simulation state\n",
    "U  = tf.Variable(u_init)\n",
    "Ut = tf.Variable(ut_init)\n",
    "\n",
    "# Discretized PDE update rules\n",
    "U_ = U + eps * Ut\n",
    "Ut_ = Ut + eps * ((c ** 2) * laplace(U) - damping * Ut)\n",
    "\n",
    "# Operation to update the state\n",
    "step = tf.group(\n",
    "  U.assign(U_),\n",
    "  Ut.assign(Ut_))\n",
    "\n",
    "# Initialize state to initial conditions\n",
    "tf.global_variables_initializer().run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally run 1000 steps and display pond after every step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run 1000 steps of PDE\n",
    "for i in range(1000):\n",
    "  # Step simulation\n",
    "  step.run({eps: 0.03, damping: 0.04, c: 3.0})\n",
    "  DisplayArray(U.eval(), rng=[-0.1, 0.1])\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now feel free to run the code. Mathematical explanation is coming."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mathematics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try formulate this code from mathematical point of view.\n",
    "\n",
    "This example is a numerical solution ([Euler's method](https://en.wikipedia.org/wiki/Numerical_methods_for_ordinary_differential_equations#Euler_method)) of [wave equation](https://en.wikipedia.org/wiki/Wave_equation) (second order Partial Differencian Equation - PDE). It's quite hard to model PDEs (and computationary expensive?), that's why PDE was transformed into ODE (oridinary differential equation), which only has one differentiable variable - time. And can be easily computed with Euler's method.\n",
    "\n",
    "Transformation of PDE to ODE is done with Laplacian transformation. In particular, [discrete Laplacian operator](https://en.wikipedia.org/wiki/Discrete_Laplace_operator) (very rough approximation of second derivative) was used. More precisely isotropic discrete Laplacian operator. Isotropic discrete Laplacian operator is just a 3x3 matrix (convolutional kernel) in our case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wave equation with Euler's method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, this problem has analytical solutions, e.g. if we restrict our waves to be monochomatic (single frequency), cylindrical waves in cylindrical coordinate system ([example](http://farside.ph.utexas.edu/teaching/315/Waves/node47.html)). So instead of brute force approximation of second derivatives, we can compute bunch of sin/cos functions and then project cylindrical coordinates to euclidean. But this at least requires careful analytical equations preparation, which can take a time. So let's look on numerical solution instead.\n",
    "\n",
    "We want to modify a wave function U(x,y), so it's values can be computed using Euler's method. For Euler we need first order differential equations, but wave function is a second order. This means we need to apply Euler's method twice.\n",
    "\n",
    "Initial [wave equation](https://en.wikipedia.org/wiki/Wave_equation#Introduction) looks like\n",
    "\n",
    "\\begin{equation} \n",
    " \\frac{{\\partial ^2 u}}{{\\partial t^2 }} = {{c^2 \\Delta u}}\n",
    "\\end{equation}\n",
    "\n",
    "Which is a second direvative $u''$. Let's write discrete equations for $u$, where $\\Delta t$ is a time difference\n",
    "\n",
    "\\begin{equation} \n",
    " u_0(x,y) = C\\\\\n",
    " u_{n+1}(x,y) = u_n(x,y) + u'_n(x,y) \\Delta t\\\\\n",
    " u'_{n+1}(x,y) = u'_n(x,y) + u''_n(x,y) \\Delta t\\\\\n",
    "\\end{equation}\n",
    "\n",
    "We know initial conditions $C$ and we also can replace $u''$ with right part of wave equation.\n",
    "\n",
    "\\begin{equation} \n",
    " u'_{n+1}(x,y) = u'_n(x,y) + c^2 \\Delta u \\Delta t\\\\\n",
    "\\end{equation}\n",
    "\n",
    "Let's also add reasoning behind wave dampling. Assuming this is a friction force, which for small speeds proportional to speed.\n",
    "\n",
    "\\begin{equation} \n",
    " u'_{n+1}(x,y) = u'_n(x,y) + (c^2 \\Delta u - k_{dampling} u'_n(x,y)) \\Delta t\\\\\n",
    "\\end{equation}\n",
    "\n",
    "Final form that is used in code is\n",
    "\n",
    "\\begin{equation}\n",
    " u_0(x,y) = C\\\\\n",
    " u_{n+1}(x,y) = u_n(x,y) + u'_n(x,y) \\Delta t\\\\\n",
    " u'_{n+1}(x,y) = u'_n(x,y) + (c^2 \\Delta u - k_{dampling} u'_n(x,y)) \\Delta t\\\\\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discrete Laplacian operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Laplacian can be a tough thing to understand actually. But let me try to explain in simple words. For detailed explanation look [here](https://ocw.mit.edu/courses/mathematics/18-03-differential-equations-spring-2010/video-lectures/lecture-19-introduction-to-the-laplace-transform/) (MIT lecture), for intuitions look [here](https://dsp.stackexchange.com/questions/11008/intuitive-interpretation-of-laplace-transform).\n",
    "\n",
    "Small context about [Fourier transform](https://en.wikipedia.org/wiki/Fourier_transform) (easier intuition).\n",
    "\n",
    "In our case we have some signal (wave), it was proven that **every signal can be broken into parts**. In case, of Fourier transform signal can be described as a **sum of harmonics (sinusoids)**. In other words, Fourier transform breaks **ANY** complex signal into bunch of simple sinusoids. Fourier transform is a special case of Laplace transform.\n",
    "\n",
    "In case of Laplace transform signal can be described by it’s \"moments\" (i.e. mean and variance, first and second derivative respectively). Put simpler (for our case), we can extract enough information from neighbours spatial points to estimate our next value (i.e. move from spatial x,y variables to time variable only). Just to remember, Laplacian transformation allows partial differential equation (PDE) to become ordinary differential equation (ODE), which is much simpler to solve.\n",
    "\n",
    "For numerical solutions discrete Laplace operator usually used with convolution. Most frequent use case is image edge detection. Basically we slide the image with special filter (kernel). Kernel is just a 3x3 matrix that is an rough approximation of analytical Laplace transform. Multiplying neighbour pixels values with kernel and then taking a sum of all values, gives us second derivative (i.e. speed of intensity/color change) that is then used in wave equation.\n",
    "\n",
    "Plots of non-isotropic (left) and isotropic Laplacian kernels.\n",
    "\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/thumb/e/ee/Laplacetf.png/600px-Laplacetf.png)\n",
    "[source wikipedia](https://de.wikipedia.org/wiki/Laplace-Filter)\n",
    "\n",
    "Small note, author of Tensorflow example used kernel matrix that for some reason was multiplied by 2 (may be i'm missing smth?). According to [wikipedia](https://en.wikipedia.org/wiki/Discrete_Laplace_operator#Implementation_via_operator_discretization), isotropic Laplace convolution kernel is\n",
    "\n",
    "\n",
    "\\begin{bmatrix}\n",
    "    0.25 & 0.5 & 0.25 \\\\\n",
    "    0.5 & -3 & 0.5 \\\\\n",
    "    0.25 & 0.5 & 0.25\n",
    "\\end{bmatrix}\n",
    "\n",
    "One more time, **Laplacian kernel can be used to get rough approximation of the second partial derivative** of the function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Physical parameters of waves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just a few notes about physical parameters of the waves (wave length, frequency). Because of numerical approximation limiations it seems impossible to get a single harmonic wave.\n",
    "\n",
    "For example, single harmonic cylindrical wave should have constant frequency (constant distance between wave crests), but as experiments show distance is changing. I assume this is because that initial wave contains multiple harmonics, so eventually they are splitting up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this blog post, i've described results of my small research regarding math background of Tensorflow example [Partial Differential Equations](https://www.tensorflow.org/tutorials/non-ml/pdes). As a result, i've added speed parameter and corrected Laplace kernel for isotropic case."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
